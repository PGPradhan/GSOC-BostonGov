To ensure the robustness of the AI model, I plan to follow the following approach:

Data Collection and Preparation: Collect a large amount of data/images from the 311 apps (provided by boston.gov) and the internet, with various lighting conditions, angles, and levels of clarity. Preprocess the images to standardize their format, size, and quality.

Model Selection: Choose a suitable AI model for image recognition, such as a Convolutional Neural Network (CNN). I am open to exploring other models as I learn more about the project.

Training: Train the selected model using the prepared dataset. I will check the accuracy and then build an API of the model.

Integration: Integrate the trained model into the 311 apps' infrastructure, allowing residents to easily snap a photo of an issue and submit a request. Provide feedback to users on the status of their requests.

Day 0: Create a githun repository. Started with the frontend first by creating a react-app. 

Day 1 : Done with creating a basic React UI for image recognition.

Day 2:  Tried React and Tensorflow integration

Day 3: Did some research on picking the model of better accuracy

Day 4: Tested YOLOV8 having CNN on the custom dataset

Day 5: Worked on Images and labels of dataset

Day 6 : Developed a Geotag system to get location information from Image